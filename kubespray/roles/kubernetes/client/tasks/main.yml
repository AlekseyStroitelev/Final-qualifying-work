---
- name: Set external kube-apiserver endpoint
  set_fact:
    # noqa: jinja[spacing]
    external_apiserver_address: >-
      {%- if loadbalancer_apiserver is defined and loadbalancer_apiserver.address is defined -%}
      {{ loadbalancer_apiserver.address }}
      {%- elif kubeconfig_localhost_ansible_host is defined and kubeconfig_localhost_ansible_host -%}
      {{ hostvars[groups['kube_control_plane'][0]].ansible_host }}
      {%- else -%}
      {{ kube_apiserver_access_address }}
      {%- endif -%}
    # noqa: jinja[spacing]
    external_apiserver_port: >-
      {%- if loadbalancer_apiserver is defined and loadbalancer_apiserver.address is defined and loadbalancer_apiserver.port is defined -%}
      {{ loadbalancer_apiserver.port | default(kube_apiserver_port) }}
      {%- else -%}
      {{ kube_apiserver_port }}
      {%- endif -%}
  tags:
    - facts

- name: Create kube config dir for current/ansible become user
  file:
    path: "{{ ansible_env.HOME | default('/root') }}/.kube"
    mode: "0700"
    state: directory

- name: Copy admin kubeconfig to current/ansible become user home
  copy:
    src: "{{ kube_config_dir }}/admin.conf"
    dest: "{{ ansible_env.HOME | default('/root') }}/.kube/config"
    remote_src: yes
    mode: "0600"
    backup: yes

- name: Create kube artifacts dir
  file:
    path: "{{ artifacts_dir }}"
    mode: "0750"
    state: directory
  delegate_to: localhost
  connection: local
  become: no
  run_once: yes
  when: kubeconfig_localhost

- name: Wait for k8s apiserver
  wait_for:
    host: "{{ kube_apiserver_access_address }}"
    port: "{{ kube_apiserver_port }}"
    timeout: 180

- name: Get admin kubeconfig from remote host
  slurp:
    src: "{{ kube_config_dir }}/admin.conf"
  run_once: yes
  register: raw_admin_kubeconfig
  when: kubeconfig_localhost

- name: Convert kubeconfig to YAML
  set_fact:
    admin_kubeconfig: "{{ raw_admin_kubeconfig.content | b64decode | from_yaml }}"
  when: kubeconfig_localhost

- name: Override username in kubeconfig
  set_fact:
    final_admin_kubeconfig: "{{ admin_kubeconfig | combine(override_cluster_name, recursive=true) | combine(override_context, recursive=true) | combine(override_user, recursive=true) }}"
  vars:
    cluster_infos: "{{ admin_kubeconfig['clusters'][0]['cluster'] }}"
    user_certs: "{{ admin_kubeconfig['users'][0]['user'] }}"
    username: "kubernetes-admin-{{ cluster_name }}"
    context: "kubernetes-admin-{{ cluster_name }}@{{ cluster_name }}"
    override_cluster_name: "{{ {'clusters': [{'cluster': (cluster_infos | combine({'server': 'https://' + external_apiserver_address + ':' + (external_apiserver_port | string)})), 'name': cluster_name}]} }}"
    override_context: "{{ {'contexts': [{'context': {'user': username, 'cluster': cluster_name}, 'name': context}], 'current-context': context} }}"
    override_user: "{{ {'users': [{'name': username, 'user': user_certs}]} }}"
  when: kubeconfig_localhost

- name: Write admin kubeconfig on ansible host
  copy:
    content: "{{ final_admin_kubeconfig | to_nice_yaml(indent=2) }}"
    dest: "{{ artifacts_dir }}/admin.conf"
    mode: 0600
  delegate_to: localhost
  connection: local
  become: no
  run_once: yes
  when: kubeconfig_localhost

- name: Copy kubectl binary to ansible host
  fetch:
    src: "{{ bin_dir }}/kubectl"
    dest: "{{ artifacts_dir }}/kubectl"
    flat: yes
    validate_checksum: no
  register: copy_binary_result
  until: copy_binary_result is not failed
  retries: 20
  become: no
  run_once: yes
  when: kubectl_localhost

- name: Create helper script kubectl.sh on ansible host
  copy:
    content: |
      #!/bin/bash
      ${BASH_SOURCE%/*}/kubectl --kubeconfig=${BASH_SOURCE%/*}/admin.conf "$@"
    dest: "{{ artifacts_dir }}/kubectl.sh"
    mode: 0755
  become: no
  run_once: yes
  delegate_to: localhost
  connection: local
  when: kubectl_localhost and kubeconfig_localhost

- name: Create address-pool manifest
  become: true
  copy:
    dest: /home/ubuntu/address-pool.yaml
    owner: ubuntu
    group: ubuntu
    mode: '0644'
    content: |
      apiVersion: metallb.io/v1beta1
      kind: IPAddressPool
      metadata:
        name: default-pool
        namespace: metallb-system
      spec:
        addresses:
        - {{ hostvars['node3'].ansible_host }}/32
      ---
      apiVersion: metallb.io/v1beta1
      kind: L2Advertisement
      metadata:
        name: default-l2
        namespace: metallb-system
      spec:
        ipAddressPools:
        - default-pool

- name: Create app manifest
  become: true
  copy:
    dest: /home/ubuntu/app.yaml
    owner: ubuntu
    group: ubuntu
    mode: '0644'
    content: |
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: my-deployment
        namespace: monitoring
        labels:
          app: my-app
      spec:
        replicas: 2
        selector:
          matchLabels:
            app: my-app
        template:
          metadata:
            labels:
              app: my-app
          spec:
            containers:
            - name: my-app
              image: makaron7321/nginx-test-app:1.4
              ports:
              - containerPort: 80
              resources:
                requests:
                  cpu: "100m"
                  memory: "128Mi"
                limits:
                  cpu: "200m"
                  memory: "256Mi"

      ---
      apiVersion: v1
      kind: Service
      metadata:
        name: my-app-service
        namespace: monitoring
      spec:
        selector:
          app: my-app
        ports:
          - protocol: TCP
            port: 80
            targetPort: 80
        type: ClusterIP

- name: Create ingress manifest
  become: true
  copy:
    dest: /home/ubuntu/ingress.yaml
    owner: ubuntu
    group: ubuntu
    mode: '0644'
    content: |
      apiVersion: networking.k8s.io/v1
      kind: Ingress
      metadata:
        name: my-ingress
        namespace: monitoring
        annotations:
          nginx.ingress.kubernetes.io/rewrite-target: /
      spec:
        ingressClassName: nginx
        rules:
        - http:
            paths:
            - path: /
              pathType: Prefix
              backend:
                service:
                  name: prometheus-grafana
                  port:
                    number: 80
            - path: /app
              pathType: Prefix
              backend:
                service:
                  name: my-app-service
                  port:
                    number: 80

- name: Create values manifest
  become: true
  copy:
    dest: /home/ubuntu/values.yaml
    owner: ubuntu
    group: ubuntu
    mode: '0644'
    content: |
      grafana:
        service:
        adminPassword: "admin"

- name: Create sh screept
  become: true
  copy:
    dest: /home/ubuntu/screept.sh
    owner: ubuntu
    group: ubuntu
    mode: '0744'
    content: |
      #!/bin/bash

      # Функция для выполнения команды с ожиданием
      run_with_timeout() {
          echo "Выполняется: $1"
          eval $1
          local exit_code=$?
          if [ $exit_code -ne 0 ]; then
              echo "Ошибка выполнения команды: $1"
              exit $exit_code
          fi
          echo "Ожидание $2 секунд..."
          sleep $2
      }

      # Таймауты между командами (в секундах)
      TIMEOUT_SHORT=5
      TIMEOUT_MEDIUM=15
      TIMEOUT_LONG=30

      echo "Начало выполнения скрипта..."

      # Создание директории .kube и копирование конфига
      run_with_timeout "sudo mkdir /home/ubuntu/.kube" $TIMEOUT_SHORT
      run_with_timeout "sudo cp /root/.kube/config /home/ubuntu/.kube/config" $TIMEOUT_SHORT
      run_with_timeout "sudo chown ubuntu:ubuntu /home/ubuntu/.kube -R" $TIMEOUT_SHORT

      # Создание namespace'ов
      run_with_timeout "kubectl create namespace monitoring" $TIMEOUT_SHORT
      run_with_timeout "kubectl create namespace metallb-system" $TIMEOUT_SHORT

      # Добавление helm репозиториев
      run_with_timeout "helm repo add prometheus-community https://prometheus-community.github.io/helm-charts" $TIMEOUT_SHORT
      run_with_timeout "helm repo add metallb https://metallb.github.io/metallb" $TIMEOUT_SHORT

      # Обновление репозиториев
      run_with_timeout "helm repo update" $TIMEOUT_MEDIUM

      # Установка metallb
      run_with_timeout "helm install metallb metallb/metallb -n metallb-system" $TIMEOUT_LONG

      # Установка prometheus
      run_with_timeout "helm install prometheus prometheus-community/kube-prometheus-stack -n monitoring -f values.yaml" $TIMEOUT_LONG

      # Применение конфигурационных файлов
      run_with_timeout "kubectl apply -f ingress.yaml" $TIMEOUT_SHORT
      run_with_timeout "kubectl apply -f address-pool.yaml" $TIMEOUT_SHORT
      run_with_timeout "kubectl apply -f app.yaml" $TIMEOUT_SHORT

      echo "Скрипт успешно завершен!"
